{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import nltk\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# import classfiers\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import feature extraction, pipeline and model selection tools\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table('desaster_tweets', engine)\n",
    "X = df['message']\n",
    "y = df.drop(columns = ['id', 'message', 'original', 'genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the labels distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.00000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "      <td>26028.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764792</td>\n",
       "      <td>0.171892</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.417243</td>\n",
       "      <td>0.080068</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.027816</td>\n",
       "      <td>0.018096</td>\n",
       "      <td>0.033041</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>0.280352</td>\n",
       "      <td>0.082795</td>\n",
       "      <td>0.09386</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.094321</td>\n",
       "      <td>0.020363</td>\n",
       "      <td>0.052866</td>\n",
       "      <td>0.194982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.424137</td>\n",
       "      <td>0.377294</td>\n",
       "      <td>0.067180</td>\n",
       "      <td>0.493113</td>\n",
       "      <td>0.271403</td>\n",
       "      <td>0.218867</td>\n",
       "      <td>0.164449</td>\n",
       "      <td>0.133301</td>\n",
       "      <td>0.178748</td>\n",
       "      <td>0.245182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>0.205591</td>\n",
       "      <td>0.449180</td>\n",
       "      <td>0.275578</td>\n",
       "      <td>0.29164</td>\n",
       "      <td>0.103525</td>\n",
       "      <td>0.292281</td>\n",
       "      <td>0.141240</td>\n",
       "      <td>0.223771</td>\n",
       "      <td>0.396195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            related       request         offer   aid_related  medical_help  \\\n",
       "count  26028.000000  26028.000000  26028.000000  26028.000000  26028.000000   \n",
       "mean       0.764792      0.171892      0.004534      0.417243      0.080068   \n",
       "std        0.424137      0.377294      0.067180      0.493113      0.271403   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       medical_products  search_and_rescue      security      military  \\\n",
       "count      26028.000000       26028.000000  26028.000000  26028.000000   \n",
       "mean           0.050446           0.027816      0.018096      0.033041   \n",
       "std            0.218867           0.164449      0.133301      0.178748   \n",
       "min            0.000000           0.000000      0.000000      0.000000   \n",
       "25%            0.000000           0.000000      0.000000      0.000000   \n",
       "50%            0.000000           0.000000      0.000000      0.000000   \n",
       "75%            0.000000           0.000000      0.000000      0.000000   \n",
       "max            1.000000           1.000000      1.000000      1.000000   \n",
       "\n",
       "              water      ...         aid_centers  other_infrastructure  \\\n",
       "count  26028.000000      ...        26028.000000          26028.000000   \n",
       "mean       0.064239      ...            0.011872              0.044222   \n",
       "std        0.245182      ...            0.108311              0.205591   \n",
       "min        0.000000      ...            0.000000              0.000000   \n",
       "25%        0.000000      ...            0.000000              0.000000   \n",
       "50%        0.000000      ...            0.000000              0.000000   \n",
       "75%        0.000000      ...            0.000000              0.000000   \n",
       "max        1.000000      ...            1.000000              1.000000   \n",
       "\n",
       "       weather_related        floods        storm          fire    earthquake  \\\n",
       "count     26028.000000  26028.000000  26028.00000  26028.000000  26028.000000   \n",
       "mean          0.280352      0.082795      0.09386      0.010834      0.094321   \n",
       "std           0.449180      0.275578      0.29164      0.103525      0.292281   \n",
       "min           0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "50%           0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "75%           1.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "max           1.000000      1.000000      1.00000      1.000000      1.000000   \n",
       "\n",
       "               cold  other_weather  direct_report  \n",
       "count  26028.000000   26028.000000   26028.000000  \n",
       "mean       0.020363       0.052866       0.194982  \n",
       "std        0.141240       0.223771       0.396195  \n",
       "min        0.000000       0.000000       0.000000  \n",
       "25%        0.000000       0.000000       0.000000  \n",
       "50%        0.000000       0.000000       0.000000  \n",
       "75%        0.000000       0.000000       0.000000  \n",
       "max        1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of categories is unbalanced. This means that accuracy is not suitable as performance score. In this notebook precision, recall and f1 score will be used with macro averaging method to evaluate model predictions. Macro averaging means the scores for all labels are avaraged with the same weights as if the distribution was uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text): \n",
    "    # remove non-letter characters\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text.lower())\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    " \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NounsExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def get_nouns(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        nouns =[]\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            nouns = nouns + [word.lower() for word,pos in pos_tags if pos == 'NN']\n",
    "        return ' '.join(nouns)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.get_nouns)\n",
    "        return X_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cv(pipeline, parameters):\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid = parameters, verbose = 5, n_jobs = -1, scoring = 'f1_macro', refit = True,\n",
    "                     return_train_score = False)\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(y_test, y_pred, print_report):\n",
    "    f1 = []\n",
    "    prcs = []\n",
    "    recl = []\n",
    "    rocauc = []\n",
    "    for i, label in enumerate(y.columns):\n",
    "        true = y_test[label].values\n",
    "        pred = y_pred[label].values\n",
    "        if print_report:\n",
    "            print('Classification result for category \\\"{}\\\":'.format(label))\n",
    "            print(classification_report(true, pred))\n",
    "        f1.append((f1_score(true, pred, average = 'macro')))\n",
    "        prcs.append(precision_score(true, pred, average = 'macro'))\n",
    "        recl.append(recall_score(true, pred, average = 'macro'))\n",
    "        rocauc.append(roc_auc_score(true, pred, average = 'macro'))\n",
    "\n",
    "    return (pd.DataFrame.from_dict({'label':y.columns, 'precision':prcs, 'recall':recl, 'f1':f1, 'roc_auc':rocauc}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Train \"related\" classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During data analysis it was shown that only messages which are labeled \"related\" contain other labels as well. One approach would be the following:\n",
    "- First classfier will be trained for \"related\" label. This feature also has higher importance as it helps to filter out messages related to disaster.\n",
    "\n",
    "- Second classifier will be trained for remaining labels to identify different labels for the categories based on experience with \"related\" classifier ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"related\" column is right-heavy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e663955c0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['related']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with imbalanced classes is complicated. To compensate for imbalance a function will be introduced to simply pad the underrepresented class until the proportion of minority class is in desired range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padToBalance(X, y):\n",
    "    # find minority class\n",
    "    if((y.sum() / y.shape[0]) > 0.5):\n",
    "        minority = 0\n",
    "    else:\n",
    "        minority = 1\n",
    "    # initialize outputs\n",
    "    X_bal = X\n",
    "    y_bal = y\n",
    "    # pad the data until minority class is at least 25%\n",
    "    while((y_bal == minority).sum() < 0.25 * y.shape[0]):\n",
    "        X_bal = pd.concat([X_bal, X[y == minority]])\n",
    "        y_bal = pd.concat([y_bal, y[y == minority]])\n",
    "    \n",
    "    return X_bal, y_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.49261090\n",
      "Validation score: 0.844463\n",
      "Iteration 2, loss = 0.30770320\n",
      "Validation score: 0.869764\n",
      "Iteration 3, loss = 0.22575626\n",
      "Validation score: 0.880962\n",
      "Iteration 4, loss = 0.17538118\n",
      "Validation score: 0.883036\n",
      "Iteration 5, loss = 0.14188785\n",
      "Validation score: 0.887599\n",
      "Iteration 6, loss = 0.11959376\n",
      "Validation score: 0.885525\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...e,\n",
       "       solver='adam', tol=0.01, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bal, y_train_bal = padToBalance(X_train, y_train['related'])\n",
    "\n",
    "MLPC_pipeline = Pipeline([\n",
    "    #('noun', NounsExtractor()),\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    ('clf', MLPClassifier(activation='relu', alpha=0.001, batch_size=200, beta_1=0.9,\n",
    "                           beta_2=0.999, early_stopping=True, epsilon=1e-8,\n",
    "                           hidden_layer_sizes=(55), learning_rate='constant',\n",
    "                           learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "                           nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "                           solver='adam', tol=0.01, validation_fraction=0.1, verbose=True,\n",
    "                           warm_start=False))\n",
    "])\n",
    "\n",
    "MLPC_pipeline.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.65      0.62      1540\n",
      "          1       0.89      0.87      0.88      4967\n",
      "\n",
      "avg / total       0.82      0.82      0.82      6507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = MLPC_pipeline.predict(X_test)\n",
    "true = y_test['related'].values\n",
    "pred = np.squeeze(y_pred)\n",
    "print(classification_report(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score (macro-averaged) 0.757396086901\n",
      "F1 score (macro-averaged) 0.75150687524\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score (macro-averaged)', roc_auc_score(true, pred, average = 'macro'))\n",
    "print('F1 score (macro-averaged)', f1_score(true, pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size=200, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=55, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.01, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPC_pipeline.named_steps['clf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Training categories classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data needs to be balanced. Instead of a multi-output classifier we will use a dictionary of pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier 0 of 35 for \"related\"\n",
      "0.619798365349\n",
      "Iteration 1, loss = 0.49261090\n",
      "Validation score: 0.844463\n",
      "Iteration 2, loss = 0.30770320\n",
      "Validation score: 0.869764\n",
      "Iteration 3, loss = 0.22575626\n",
      "Validation score: 0.880962\n",
      "Iteration 4, loss = 0.17538118\n",
      "Validation score: 0.883036\n",
      "Iteration 5, loss = 0.14188785\n",
      "Validation score: 0.887599\n",
      "Iteration 6, loss = 0.11959376\n",
      "Validation score: 0.885525\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 1 of 35 for \"request\"\n",
      "0.293245901639\n",
      "Iteration 1, loss = 0.44244321\n",
      "Validation score: 0.884615\n",
      "Iteration 2, loss = 0.27639467\n",
      "Validation score: 0.893794\n",
      "Iteration 3, loss = 0.20483071\n",
      "Validation score: 0.899476\n",
      "Iteration 4, loss = 0.16200403\n",
      "Validation score: 0.912150\n",
      "Iteration 5, loss = 0.13456145\n",
      "Validation score: 0.916084\n",
      "Iteration 6, loss = 0.11307846\n",
      "Validation score: 0.920455\n",
      "Iteration 7, loss = 0.09763643\n",
      "Validation score: 0.923951\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 2 of 35 for \"offer\"\n",
      "0.202741525076\n",
      "Iteration 1, loss = 0.24083980\n",
      "Validation score: 0.990562\n",
      "Iteration 2, loss = 0.04161673\n",
      "Validation score: 0.994666\n",
      "Iteration 3, loss = 0.01882115\n",
      "Validation score: 0.995486\n",
      "Iteration 4, loss = 0.01136568\n",
      "Validation score: 0.995076\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 3 of 35 for \"aid_related\"\n",
      "0.419087136929\n",
      "Iteration 1, loss = 0.56078006\n",
      "Validation score: 0.792627\n",
      "Iteration 2, loss = 0.39827053\n",
      "Validation score: 0.791603\n",
      "Iteration 3, loss = 0.31475136\n",
      "Validation score: 0.790579\n",
      "Iteration 4, loss = 0.25884125\n",
      "Validation score: 0.776242\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 4 of 35 for \"medical_help\"\n",
      "0.258506772382\n",
      "Iteration 1, loss = 0.48206288\n",
      "Validation score: 0.871181\n",
      "Iteration 2, loss = 0.25134512\n",
      "Validation score: 0.918662\n",
      "Iteration 3, loss = 0.15414974\n",
      "Validation score: 0.936829\n",
      "Iteration 4, loss = 0.10184412\n",
      "Validation score: 0.945500\n",
      "Iteration 5, loss = 0.07216739\n",
      "Validation score: 0.946325\n",
      "Iteration 6, loss = 0.05367307\n",
      "Validation score: 0.955822\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 5 of 35 for \"medical_products\"\n",
      "0.211162671889\n",
      "Iteration 1, loss = 0.43598588\n",
      "Validation score: 0.916986\n",
      "Iteration 2, loss = 0.19713872\n",
      "Validation score: 0.950617\n",
      "Iteration 3, loss = 0.10703073\n",
      "Validation score: 0.968923\n",
      "Iteration 4, loss = 0.06623838\n",
      "Validation score: 0.976586\n",
      "Iteration 5, loss = 0.04588967\n",
      "Validation score: 0.978714\n",
      "Iteration 6, loss = 0.03409292\n",
      "Validation score: 0.979566\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 6 of 35 for \"search_and_rescue\"\n",
      "0.213333886836\n",
      "Iteration 1, loss = 0.42475491\n",
      "Validation score: 0.927356\n",
      "Iteration 2, loss = 0.15182594\n",
      "Validation score: 0.977584\n",
      "Iteration 3, loss = 0.07357767\n",
      "Validation score: 0.980490\n",
      "Iteration 4, loss = 0.04395946\n",
      "Validation score: 0.986716\n",
      "Iteration 5, loss = 0.02955111\n",
      "Validation score: 0.984226\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 7 of 35 for \"security\"\n",
      "0.213503425079\n",
      "Iteration 1, loss = 0.42457522\n",
      "Validation score: 0.948318\n",
      "Iteration 2, loss = 0.13725543\n",
      "Validation score: 0.986054\n",
      "Iteration 3, loss = 0.06157788\n",
      "Validation score: 0.995488\n",
      "Iteration 4, loss = 0.03438381\n",
      "Validation score: 0.993437\n",
      "Iteration 5, loss = 0.02260155\n",
      "Validation score: 0.993437\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 8 of 35 for \"military\"\n",
      "0.212510425354\n",
      "Iteration 1, loss = 0.33305612\n",
      "Validation score: 0.969975\n",
      "Iteration 2, loss = 0.09852625\n",
      "Validation score: 0.988324\n",
      "Iteration 3, loss = 0.04518485\n",
      "Validation score: 0.993328\n",
      "Iteration 4, loss = 0.02476232\n",
      "Validation score: 0.994162\n",
      "Iteration 5, loss = 0.01584378\n",
      "Validation score: 0.994579\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 9 of 35 for \"water\"\n",
      "0.215724161621\n",
      "Iteration 1, loss = 0.43131687\n",
      "Validation score: 0.934736\n",
      "Iteration 2, loss = 0.15845138\n",
      "Validation score: 0.962216\n",
      "Iteration 3, loss = 0.08774320\n",
      "Validation score: 0.967368\n",
      "Iteration 4, loss = 0.05833378\n",
      "Validation score: 0.974667\n",
      "Iteration 5, loss = 0.04165336\n",
      "Validation score: 0.978102\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 10 of 35 for \"food\"\n",
      "0.275805844726\n",
      "Iteration 1, loss = 0.44992928\n",
      "Validation score: 0.920569\n",
      "Iteration 2, loss = 0.18681319\n",
      "Validation score: 0.949415\n",
      "Iteration 3, loss = 0.10754595\n",
      "Validation score: 0.969064\n",
      "Iteration 4, loss = 0.07365640\n",
      "Validation score: 0.969900\n",
      "Iteration 5, loss = 0.05423935\n",
      "Validation score: 0.976171\n",
      "Iteration 6, loss = 0.04204279\n",
      "Validation score: 0.981605\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 11 of 35 for \"shelter\"\n",
      "0.226392936366\n",
      "Iteration 1, loss = 0.45389856\n",
      "Validation score: 0.913043\n",
      "Iteration 2, loss = 0.19551225\n",
      "Validation score: 0.948261\n",
      "Iteration 3, loss = 0.11434813\n",
      "Validation score: 0.960870\n",
      "Iteration 4, loss = 0.07795408\n",
      "Validation score: 0.966957\n",
      "Iteration 5, loss = 0.05616878\n",
      "Validation score: 0.974348\n",
      "Iteration 6, loss = 0.04329378\n",
      "Validation score: 0.972609\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 12 of 35 for \"clothing\"\n",
      "0.204134045814\n",
      "Iteration 1, loss = 0.33762514\n",
      "Validation score: 0.968944\n",
      "Iteration 2, loss = 0.08877620\n",
      "Validation score: 0.987164\n",
      "Iteration 3, loss = 0.04244029\n",
      "Validation score: 0.992961\n",
      "Iteration 4, loss = 0.02594044\n",
      "Validation score: 0.995031\n",
      "Iteration 5, loss = 0.01830464\n",
      "Validation score: 0.995859\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 13 of 35 for \"money\"\n",
      "0.210881536996\n",
      "Iteration 1, loss = 0.38705151\n",
      "Validation score: 0.953228\n",
      "Iteration 2, loss = 0.10729106\n",
      "Validation score: 0.984272\n",
      "Iteration 3, loss = 0.04832488\n",
      "Validation score: 0.987169\n",
      "Iteration 4, loss = 0.02823610\n",
      "Validation score: 0.990894\n",
      "Iteration 5, loss = 0.01894461\n",
      "Validation score: 0.991308\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 14 of 35 for \"missing_people\"\n",
      "0.20467185762\n",
      "Iteration 1, loss = 0.36754578\n",
      "Validation score: 0.964580\n",
      "Iteration 2, loss = 0.09889974\n",
      "Validation score: 0.988056\n",
      "Iteration 3, loss = 0.04430751\n",
      "Validation score: 0.991763\n",
      "Iteration 4, loss = 0.02622009\n",
      "Validation score: 0.994646\n",
      "Iteration 5, loss = 0.01821707\n",
      "Validation score: 0.996293\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 15 of 35 for \"refugees\"\n",
      "0.211694978922\n",
      "Iteration 1, loss = 0.41756347\n",
      "Validation score: 0.935726\n",
      "Iteration 2, loss = 0.15705500\n",
      "Validation score: 0.977045\n",
      "Iteration 3, loss = 0.07591846\n",
      "Validation score: 0.987896\n",
      "Iteration 4, loss = 0.04544485\n",
      "Validation score: 0.987479\n",
      "Iteration 5, loss = 0.03250175\n",
      "Validation score: 0.992070\n",
      "Iteration 6, loss = 0.02333265\n",
      "Validation score: 0.992070\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 16 of 35 for \"death\"\n",
      "0.225006243236\n",
      "Iteration 1, loss = 0.41383101\n",
      "Validation score: 0.931336\n",
      "Iteration 2, loss = 0.15174999\n",
      "Validation score: 0.966708\n",
      "Iteration 3, loss = 0.07543684\n",
      "Validation score: 0.980025\n",
      "Iteration 4, loss = 0.04635610\n",
      "Validation score: 0.986267\n",
      "Iteration 5, loss = 0.03200654\n",
      "Validation score: 0.987099\n",
      "Iteration 6, loss = 0.02367572\n",
      "Validation score: 0.987516\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 17 of 35 for \"other_aid\"\n",
      "0.233553524568\n",
      "Iteration 1, loss = 0.55048639\n",
      "Validation score: 0.781547\n",
      "Iteration 2, loss = 0.37961462\n",
      "Validation score: 0.812754\n",
      "Iteration 3, loss = 0.27185304\n",
      "Validation score: 0.842605\n",
      "Iteration 4, loss = 0.19953815\n",
      "Validation score: 0.865219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.14864432\n",
      "Validation score: 0.877431\n",
      "Iteration 6, loss = 0.11267283\n",
      "Validation score: 0.899593\n",
      "Iteration 7, loss = 0.08864842\n",
      "Validation score: 0.897784\n",
      "Iteration 8, loss = 0.07052243\n",
      "Validation score: 0.901854\n",
      "Iteration 9, loss = 0.06089795\n",
      "Validation score: 0.903211\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 18 of 35 for \"infrastructure_related\"\n",
      "0.217879489157\n",
      "Iteration 1, loss = 0.50418777\n",
      "Validation score: 0.844901\n",
      "Iteration 2, loss = 0.28136624\n",
      "Validation score: 0.916024\n",
      "Iteration 3, loss = 0.15907674\n",
      "Validation score: 0.946444\n",
      "Iteration 4, loss = 0.09737645\n",
      "Validation score: 0.965296\n",
      "Iteration 5, loss = 0.06479439\n",
      "Validation score: 0.968723\n",
      "Iteration 6, loss = 0.04778471\n",
      "Validation score: 0.971722\n",
      "Iteration 7, loss = 0.03429413\n",
      "Validation score: 0.977292\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 19 of 35 for \"transport\"\n",
      "0.225209104906\n",
      "Iteration 1, loss = 0.46391846\n",
      "Validation score: 0.897255\n",
      "Iteration 2, loss = 0.21181256\n",
      "Validation score: 0.952163\n",
      "Iteration 3, loss = 0.10992130\n",
      "Validation score: 0.967970\n",
      "Iteration 4, loss = 0.06731844\n",
      "Validation score: 0.978369\n",
      "Iteration 5, loss = 0.04562363\n",
      "Validation score: 0.981281\n",
      "Iteration 6, loss = 0.03577581\n",
      "Validation score: 0.981281\n",
      "Iteration 7, loss = 0.02717476\n",
      "Validation score: 0.979201\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 20 of 35 for \"buildings\"\n",
      "0.211693119442\n",
      "Iteration 1, loss = 0.43618535\n",
      "Validation score: 0.929817\n",
      "Iteration 2, loss = 0.16681369\n",
      "Validation score: 0.961293\n",
      "Iteration 3, loss = 0.09084959\n",
      "Validation score: 0.972352\n",
      "Iteration 4, loss = 0.05636816\n",
      "Validation score: 0.981710\n",
      "Iteration 5, loss = 0.03782820\n",
      "Validation score: 0.982561\n",
      "Iteration 6, loss = 0.02790840\n",
      "Validation score: 0.981710\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 21 of 35 for \"electricity\"\n",
      "0.215519717674\n",
      "Iteration 1, loss = 0.35529218\n",
      "Validation score: 0.968404\n",
      "Iteration 2, loss = 0.10061160\n",
      "Validation score: 0.987690\n",
      "Iteration 3, loss = 0.04630948\n",
      "Validation score: 0.988921\n",
      "Iteration 4, loss = 0.02760711\n",
      "Validation score: 0.992204\n",
      "Iteration 5, loss = 0.01704039\n",
      "Validation score: 0.992204\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 22 of 35 for \"tools\"\n",
      "0.204991598705\n",
      "Iteration 1, loss = 0.30698387\n",
      "Validation score: 0.985252\n",
      "Iteration 2, loss = 0.06314066\n",
      "Validation score: 0.996723\n",
      "Iteration 3, loss = 0.02576855\n",
      "Validation score: 0.997132\n",
      "Iteration 4, loss = 0.01473338\n",
      "Validation score: 0.997542\n",
      "Iteration 5, loss = 0.00998915\n",
      "Validation score: 0.997542\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 23 of 35 for \"hospitals\"\n",
      "0.202693769625\n",
      "Iteration 1, loss = 0.35182583\n",
      "Validation score: 0.965717\n",
      "Iteration 2, loss = 0.08902246\n",
      "Validation score: 0.993804\n",
      "Iteration 3, loss = 0.03800488\n",
      "Validation score: 0.995456\n",
      "Iteration 4, loss = 0.02137739\n",
      "Validation score: 0.995043\n",
      "Iteration 5, loss = 0.01406547\n",
      "Validation score: 0.997522\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 24 of 35 for \"shops\"\n",
      "0.203296027549\n",
      "Iteration 1, loss = 0.26865901\n",
      "Validation score: 0.993852\n",
      "Iteration 2, loss = 0.04631571\n",
      "Validation score: 0.998361\n",
      "Iteration 3, loss = 0.01894848\n",
      "Validation score: 0.998770\n",
      "Iteration 4, loss = 0.01101429\n",
      "Validation score: 0.999180\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 25 of 35 for \"aid_centers\"\n",
      "0.202348951656\n",
      "Iteration 1, loss = 0.36058309\n",
      "Validation score: 0.974783\n",
      "Iteration 2, loss = 0.09418020\n",
      "Validation score: 0.996693\n",
      "Iteration 3, loss = 0.03846792\n",
      "Validation score: 0.997106\n",
      "Iteration 4, loss = 0.02129575\n",
      "Validation score: 0.997106\n",
      "Iteration 5, loss = 0.01392781\n",
      "Validation score: 0.997933\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 26 of 35 for \"other_infrastructure\"\n",
      "0.214961523906\n",
      "Iteration 1, loss = 0.45613602\n",
      "Validation score: 0.901639\n",
      "Iteration 2, loss = 0.20536369\n",
      "Validation score: 0.959227\n",
      "Iteration 3, loss = 0.10342270\n",
      "Validation score: 0.977722\n",
      "Iteration 4, loss = 0.05869593\n",
      "Validation score: 0.982766\n",
      "Iteration 5, loss = 0.03770098\n",
      "Validation score: 0.983186\n",
      "Iteration 6, loss = 0.02635459\n",
      "Validation score: 0.986969\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 27 of 35 for \"weather_related\"\n",
      "0.279032836433\n",
      "Iteration 1, loss = 0.49670553\n",
      "Validation score: 0.864311\n",
      "Iteration 2, loss = 0.29401519\n",
      "Validation score: 0.873016\n",
      "Iteration 3, loss = 0.20427561\n",
      "Validation score: 0.866871\n",
      "Iteration 4, loss = 0.15502161\n",
      "Validation score: 0.868408\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 28 of 35 for \"floods\"\n",
      "0.266174661747\n",
      "Iteration 1, loss = 0.42225863\n",
      "Validation score: 0.911439\n",
      "Iteration 2, loss = 0.19310207\n",
      "Validation score: 0.943829\n",
      "Iteration 3, loss = 0.11346248\n",
      "Validation score: 0.956540\n",
      "Iteration 4, loss = 0.07527743\n",
      "Validation score: 0.968840\n",
      "Iteration 5, loss = 0.05451668\n",
      "Validation score: 0.971300\n",
      "Iteration 6, loss = 0.04042877\n",
      "Validation score: 0.973350\n",
      "Iteration 7, loss = 0.03186082\n",
      "Validation score: 0.974170\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 29 of 35 for \"storm\"\n",
      "0.235304280223\n",
      "Iteration 1, loss = 0.41980374\n",
      "Validation score: 0.916667\n",
      "Iteration 2, loss = 0.17630337\n",
      "Validation score: 0.952073\n",
      "Iteration 3, loss = 0.10034357\n",
      "Validation score: 0.962435\n",
      "Iteration 4, loss = 0.06601138\n",
      "Validation score: 0.970639\n",
      "Iteration 5, loss = 0.04693150\n",
      "Validation score: 0.970639\n",
      "Iteration 6, loss = 0.03599991\n",
      "Validation score: 0.969775\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 30 of 35 for \"fire\"\n",
      "0.202693769625\n",
      "Iteration 1, loss = 0.32077589\n",
      "Validation score: 0.969434\n",
      "Iteration 2, loss = 0.07090689\n",
      "Validation score: 0.993804\n",
      "Iteration 3, loss = 0.02679443\n",
      "Validation score: 0.997522\n",
      "Iteration 4, loss = 0.01454285\n",
      "Validation score: 0.997522\n",
      "Iteration 5, loss = 0.00953049\n",
      "Validation score: 0.997935\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 31 of 35 for \"earthquake\"\n",
      "0.233663451974\n",
      "Iteration 1, loss = 0.41499226\n",
      "Validation score: 0.938176\n",
      "Iteration 2, loss = 0.15900997\n",
      "Validation score: 0.971466\n",
      "Iteration 3, loss = 0.08787664\n",
      "Validation score: 0.975789\n",
      "Iteration 4, loss = 0.06223615\n",
      "Validation score: 0.979680\n",
      "Iteration 5, loss = 0.04423315\n",
      "Validation score: 0.981409\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 32 of 35 for \"cold\"\n",
      "0.21036119711\n",
      "Iteration 1, loss = 0.34230363\n",
      "Validation score: 0.966158\n",
      "Iteration 2, loss = 0.08395286\n",
      "Validation score: 0.990095\n",
      "Iteration 3, loss = 0.03533914\n",
      "Validation score: 0.992571\n",
      "Iteration 4, loss = 0.02085742\n",
      "Validation score: 0.993809\n",
      "Iteration 5, loss = 0.01368352\n",
      "Validation score: 0.994635\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 33 of 35 for \"other_weather\"\n",
      "0.218016493973\n",
      "Iteration 1, loss = 0.47278051\n",
      "Validation score: 0.884567\n",
      "Iteration 2, loss = 0.22747058\n",
      "Validation score: 0.943763\n",
      "Iteration 3, loss = 0.11635471\n",
      "Validation score: 0.966596\n",
      "Iteration 4, loss = 0.06977923\n",
      "Validation score: 0.972093\n",
      "Iteration 5, loss = 0.04594474\n",
      "Validation score: 0.974207\n",
      "Iteration 6, loss = 0.03523879\n",
      "Validation score: 0.978013\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Training classifier 34 of 35 for \"direct_report\"\n",
      "0.324737180862\n",
      "Iteration 1, loss = 0.47576486\n",
      "Validation score: 0.833977\n",
      "Iteration 2, loss = 0.31781296\n",
      "Validation score: 0.858859\n",
      "Iteration 3, loss = 0.24074718\n",
      "Validation score: 0.872587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.19034169\n",
      "Validation score: 0.887173\n",
      "Iteration 5, loss = 0.15717297\n",
      "Validation score: 0.892750\n",
      "Iteration 6, loss = 0.13302557\n",
      "Validation score: 0.900043\n",
      "Iteration 7, loss = 0.11480388\n",
      "Validation score: 0.894895\n",
      "Validation score did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "MLPC_pipeline_dict = {}\n",
    "countvec = CountVectorizer(tokenizer = tokenize)\n",
    "start = timeit.default_timer()\n",
    "for i,label in enumerate(y.columns):\n",
    "    MLPC_pipeline_dict[label] = Pipeline([\n",
    "        ('vect', countvec),\n",
    "        ('clf',MLPClassifier(activation='relu', alpha=0.001, batch_size=200, beta_1=0.9,\n",
    "                               beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
    "                               hidden_layer_sizes=55, learning_rate='constant',\n",
    "                               learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "                               nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "                               solver='adam', tol=0.01, validation_fraction=0.1, verbose=True,\n",
    "                               warm_start=False))\n",
    "    ])\n",
    "    print('Training classifier {} of {} for \\\"{}\\\"'.format(i, len(y.columns), label))\n",
    "    X_train_bal, y_train_bal = padToBalance(X_train, y_train[label])\n",
    "    print(y_train_bal.sum()/y_train_bal.shape[0])\n",
    "    MLPC_pipeline_dict[label].fit(X_train_bal, y_train_bal)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "MLPC_training_time = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLCP pipeline training time: 1672.25 seconds\n"
     ]
    }
   ],
   "source": [
    "print('MLCP pipeline training time: {:.2f} seconds'.format(MLPC_training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.706208\n",
       "recall       0.659678\n",
       "f1           0.676563\n",
       "rpc_auc      0.659678\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPC_pipeline_pred_dict = {}\n",
    "start = timeit.default_timer()\n",
    "for label in y.columns:\n",
    "    MLPC_pipeline_pred_dict[label] = MLPC_pipeline_dict[label].predict(X_test)\n",
    "stop = timeit.default_timer()\n",
    "MLPC_predict_time = stop - start\n",
    "    \n",
    "y_pred = pd.DataFrame.from_dict(MLPC_pipeline_pred_dict)\n",
    "results_MLPC = show_results(y_test, y_pred, print_report = False)\n",
    "results_MLPC.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLCP pipeline predict time: 104.12 seconds\n"
     ]
    }
   ],
   "source": [
    "print('MLCP pipeline predict time: {:.2f} seconds'.format(MLPC_predict_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search is computationally expensive, so it would be very time consuming to perform it on a multi output model. Also evaluation of multiple classifications will be complex. Instead grid search was applied to the \"related\" column in the section 4.1 to fine-tune MLPC parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>related</td>\n",
       "      <td>0.746369</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.751507</td>\n",
       "      <td>0.757396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request</td>\n",
       "      <td>0.796231</td>\n",
       "      <td>0.792444</td>\n",
       "      <td>0.794314</td>\n",
       "      <td>0.792444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>offer</td>\n",
       "      <td>0.498227</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>0.498381</td>\n",
       "      <td>0.498535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aid_related</td>\n",
       "      <td>0.770147</td>\n",
       "      <td>0.761365</td>\n",
       "      <td>0.764592</td>\n",
       "      <td>0.761365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medical_help</td>\n",
       "      <td>0.675020</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.647849</td>\n",
       "      <td>0.629825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medical_products</td>\n",
       "      <td>0.729963</td>\n",
       "      <td>0.678370</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.678370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.652620</td>\n",
       "      <td>0.580718</td>\n",
       "      <td>0.604507</td>\n",
       "      <td>0.580718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>security</td>\n",
       "      <td>0.550320</td>\n",
       "      <td>0.517263</td>\n",
       "      <td>0.524049</td>\n",
       "      <td>0.517263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>military</td>\n",
       "      <td>0.732017</td>\n",
       "      <td>0.664038</td>\n",
       "      <td>0.691545</td>\n",
       "      <td>0.664038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>water</td>\n",
       "      <td>0.822628</td>\n",
       "      <td>0.792788</td>\n",
       "      <td>0.806844</td>\n",
       "      <td>0.792788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>food</td>\n",
       "      <td>0.863266</td>\n",
       "      <td>0.835269</td>\n",
       "      <td>0.848497</td>\n",
       "      <td>0.835269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shelter</td>\n",
       "      <td>0.800438</td>\n",
       "      <td>0.768675</td>\n",
       "      <td>0.783400</td>\n",
       "      <td>0.768675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clothing</td>\n",
       "      <td>0.755138</td>\n",
       "      <td>0.708376</td>\n",
       "      <td>0.729294</td>\n",
       "      <td>0.708376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>money</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.653919</td>\n",
       "      <td>0.667833</td>\n",
       "      <td>0.653919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>missing_people</td>\n",
       "      <td>0.634215</td>\n",
       "      <td>0.541282</td>\n",
       "      <td>0.561818</td>\n",
       "      <td>0.541282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>refugees</td>\n",
       "      <td>0.698473</td>\n",
       "      <td>0.592483</td>\n",
       "      <td>0.623755</td>\n",
       "      <td>0.592483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>death</td>\n",
       "      <td>0.815046</td>\n",
       "      <td>0.744577</td>\n",
       "      <td>0.774821</td>\n",
       "      <td>0.744577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>other_aid</td>\n",
       "      <td>0.637915</td>\n",
       "      <td>0.602251</td>\n",
       "      <td>0.615155</td>\n",
       "      <td>0.602251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>infrastructure_related</td>\n",
       "      <td>0.609876</td>\n",
       "      <td>0.568458</td>\n",
       "      <td>0.582367</td>\n",
       "      <td>0.568458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>transport</td>\n",
       "      <td>0.702533</td>\n",
       "      <td>0.611480</td>\n",
       "      <td>0.641683</td>\n",
       "      <td>0.611480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>buildings</td>\n",
       "      <td>0.746209</td>\n",
       "      <td>0.712188</td>\n",
       "      <td>0.727711</td>\n",
       "      <td>0.712188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>electricity</td>\n",
       "      <td>0.752568</td>\n",
       "      <td>0.661006</td>\n",
       "      <td>0.696076</td>\n",
       "      <td>0.661006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tools</td>\n",
       "      <td>0.497153</td>\n",
       "      <td>0.499304</td>\n",
       "      <td>0.498226</td>\n",
       "      <td>0.499304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hospitals</td>\n",
       "      <td>0.620910</td>\n",
       "      <td>0.556705</td>\n",
       "      <td>0.576683</td>\n",
       "      <td>0.556705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>shops</td>\n",
       "      <td>0.497463</td>\n",
       "      <td>0.499691</td>\n",
       "      <td>0.498574</td>\n",
       "      <td>0.499691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aid_centers</td>\n",
       "      <td>0.604047</td>\n",
       "      <td>0.544109</td>\n",
       "      <td>0.561173</td>\n",
       "      <td>0.544109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>other_infrastructure</td>\n",
       "      <td>0.596184</td>\n",
       "      <td>0.550697</td>\n",
       "      <td>0.564304</td>\n",
       "      <td>0.550697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>weather_related</td>\n",
       "      <td>0.846555</td>\n",
       "      <td>0.815147</td>\n",
       "      <td>0.828468</td>\n",
       "      <td>0.815147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>floods</td>\n",
       "      <td>0.783831</td>\n",
       "      <td>0.739366</td>\n",
       "      <td>0.759184</td>\n",
       "      <td>0.739366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>storm</td>\n",
       "      <td>0.825738</td>\n",
       "      <td>0.770711</td>\n",
       "      <td>0.794894</td>\n",
       "      <td>0.770711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fire</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.591825</td>\n",
       "      <td>0.622447</td>\n",
       "      <td>0.591825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.914599</td>\n",
       "      <td>0.854278</td>\n",
       "      <td>0.881388</td>\n",
       "      <td>0.854278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cold</td>\n",
       "      <td>0.752120</td>\n",
       "      <td>0.642023</td>\n",
       "      <td>0.680773</td>\n",
       "      <td>0.642023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>other_weather</td>\n",
       "      <td>0.670418</td>\n",
       "      <td>0.609417</td>\n",
       "      <td>0.631786</td>\n",
       "      <td>0.609417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>direct_report</td>\n",
       "      <td>0.748291</td>\n",
       "      <td>0.742739</td>\n",
       "      <td>0.745443</td>\n",
       "      <td>0.742739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label  precision    recall        f1   roc_auc\n",
       "0                  related   0.746369  0.757396  0.751507  0.757396\n",
       "1                  request   0.796231  0.792444  0.794314  0.792444\n",
       "2                    offer   0.498227  0.498535  0.498381  0.498535\n",
       "3              aid_related   0.770147  0.761365  0.764592  0.761365\n",
       "4             medical_help   0.675020  0.629825  0.647849  0.629825\n",
       "5         medical_products   0.729963  0.678370  0.700349  0.678370\n",
       "6        search_and_rescue   0.652620  0.580718  0.604507  0.580718\n",
       "7                 security   0.550320  0.517263  0.524049  0.517263\n",
       "8                 military   0.732017  0.664038  0.691545  0.664038\n",
       "9                    water   0.822628  0.792788  0.806844  0.792788\n",
       "10                    food   0.863266  0.835269  0.848497  0.835269\n",
       "11                 shelter   0.800438  0.768675  0.783400  0.768675\n",
       "12                clothing   0.755138  0.708376  0.729294  0.708376\n",
       "13                   money   0.684796  0.653919  0.667833  0.653919\n",
       "14          missing_people   0.634215  0.541282  0.561818  0.541282\n",
       "15                refugees   0.698473  0.592483  0.623755  0.592483\n",
       "16                   death   0.815046  0.744577  0.774821  0.744577\n",
       "17               other_aid   0.637915  0.602251  0.615155  0.602251\n",
       "18  infrastructure_related   0.609876  0.568458  0.582367  0.568458\n",
       "19               transport   0.702533  0.611480  0.641683  0.611480\n",
       "20               buildings   0.746209  0.712188  0.727711  0.712188\n",
       "21             electricity   0.752568  0.661006  0.696076  0.661006\n",
       "22                   tools   0.497153  0.499304  0.498226  0.499304\n",
       "23               hospitals   0.620910  0.556705  0.576683  0.556705\n",
       "24                   shops   0.497463  0.499691  0.498574  0.499691\n",
       "25             aid_centers   0.604047  0.544109  0.561173  0.544109\n",
       "26    other_infrastructure   0.596184  0.550697  0.564304  0.550697\n",
       "27         weather_related   0.846555  0.815147  0.828468  0.815147\n",
       "28                  floods   0.783831  0.739366  0.759184  0.739366\n",
       "29                   storm   0.825738  0.770711  0.794894  0.770711\n",
       "30                    fire   0.685950  0.591825  0.622447  0.591825\n",
       "31              earthquake   0.914599  0.854278  0.881388  0.854278\n",
       "32                    cold   0.752120  0.642023  0.680773  0.642023\n",
       "33           other_weather   0.670418  0.609417  0.631786  0.609417\n",
       "34           direct_report   0.748291  0.742739  0.745443  0.742739"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_results(y_test, y_pred, print_report = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest 100 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(n_estimators = 100, min_samples_split = 4)))\n",
    "    ])\n",
    "\n",
    "start = timeit.default_timer()\n",
    "model_RF.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "RF_training_time = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF pipeline training time: 535.57 seconds\n"
     ]
    }
   ],
   "source": [
    "print('RF pipeline training time: {:.2f} seconds'.format(RF_training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "precision    0.744235\n",
       "recall       0.580015\n",
       "f1           0.596818\n",
       "roc_auc      0.580015\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "y_pred = pd.DataFrame(model_RF.predict(X_test), columns = y.columns)\n",
    "stop = timeit.default_timer()\n",
    "RF_predict_time = stop - start\n",
    "results_RF = show_results(y_test, y_pred, print_report = False)\n",
    "results_RF.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF pipeline predict time: 19.19 seconds\n"
     ]
    }
   ],
   "source": [
    "print('RF pipeline predict time: {:.2f} seconds'.format(RF_predict_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB pipeline training time: 9.80 seconds\n"
     ]
    }
   ],
   "source": [
    "model_NB = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize, stop_words = 'english')),\n",
    "        ('clf', MultiOutputClassifier(MultinomialNB(fit_prior = False)))\n",
    "    ])\n",
    "\n",
    "start = timeit.default_timer()\n",
    "model_NB.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "NB_training_time = stop - start\n",
    "\n",
    "print('NB pipeline training time: {:.2f} seconds'.format(NB_training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.610911\n",
       "recall       0.647583\n",
       "f1           0.623143\n",
       "roc_auc      0.647583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "y_pred = pd.DataFrame(model_NB.predict(X_test), columns = y.columns)\n",
    "stop = timeit.default_timer()\n",
    "NB_predict_time = stop - start\n",
    "results_NB = show_results(y_test, y_pred, print_report = False)\n",
    "results_NB.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB pipeline predict time: 3.22 seconds\n"
     ]
    }
   ],
   "source": [
    "print('NB pipeline predict time: {:.2f} seconds'.format(NB_predict_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC pipeline training time: 34.04 seconds\n"
     ]
    }
   ],
   "source": [
    "model_SVC = Pipeline([\n",
    "        #('noun', NounsExtractor()),\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize, ngram_range = (1,2), stop_words = 'english')),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(LinearSVC(class_weight = 'balanced', random_state = 1)))\n",
    "    ])\n",
    "\n",
    "start = timeit.default_timer()\n",
    "model_SVC.fit(X_train, y_train)\n",
    "stop = timeit.default_timer()\n",
    "SVC_training_time = stop - start\n",
    "\n",
    "print('Linear SVC pipeline training time: {:.2f} seconds'.format(SVC_training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.727760\n",
       "recall       0.703731\n",
       "f1           0.707707\n",
       "roc_auc      0.703731\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "y_pred = pd.DataFrame(model_SVC.predict(X_test), columns = y.columns)\n",
    "stop = timeit.default_timer()\n",
    "SVC_predict_time = stop - start\n",
    "results_SVC = show_results(y_test, y_pred, print_report = False)\n",
    "results_SVC.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC pipeline training time: 3.14 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Linear SVC pipeline predict time: {:.2f} seconds'.format(SVC_predict_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>roc_auc_SVC</th>\n",
       "      <th>roc_auc_MLPC</th>\n",
       "      <th>roc_auc_NB</th>\n",
       "      <th>roc_auc_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>related</td>\n",
       "      <td>0.740768</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.746812</td>\n",
       "      <td>0.619573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request</td>\n",
       "      <td>0.812441</td>\n",
       "      <td>0.792444</td>\n",
       "      <td>0.797583</td>\n",
       "      <td>0.718689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>offer</td>\n",
       "      <td>0.521662</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>0.497070</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aid_related</td>\n",
       "      <td>0.758708</td>\n",
       "      <td>0.761365</td>\n",
       "      <td>0.736056</td>\n",
       "      <td>0.747421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medical_help</td>\n",
       "      <td>0.713030</td>\n",
       "      <td>0.629825</td>\n",
       "      <td>0.691044</td>\n",
       "      <td>0.537495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medical_products</td>\n",
       "      <td>0.730624</td>\n",
       "      <td>0.678370</td>\n",
       "      <td>0.681997</td>\n",
       "      <td>0.561335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.607963</td>\n",
       "      <td>0.580718</td>\n",
       "      <td>0.543553</td>\n",
       "      <td>0.516104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>security</td>\n",
       "      <td>0.522627</td>\n",
       "      <td>0.517263</td>\n",
       "      <td>0.497766</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>military</td>\n",
       "      <td>0.764392</td>\n",
       "      <td>0.664038</td>\n",
       "      <td>0.727779</td>\n",
       "      <td>0.517460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>water</td>\n",
       "      <td>0.888361</td>\n",
       "      <td>0.792788</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.655482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>food</td>\n",
       "      <td>0.889475</td>\n",
       "      <td>0.835269</td>\n",
       "      <td>0.800844</td>\n",
       "      <td>0.729963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>shelter</td>\n",
       "      <td>0.832422</td>\n",
       "      <td>0.768675</td>\n",
       "      <td>0.775942</td>\n",
       "      <td>0.656826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>clothing</td>\n",
       "      <td>0.771012</td>\n",
       "      <td>0.708376</td>\n",
       "      <td>0.657694</td>\n",
       "      <td>0.541159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>money</td>\n",
       "      <td>0.719960</td>\n",
       "      <td>0.653919</td>\n",
       "      <td>0.578442</td>\n",
       "      <td>0.517573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>missing_people</td>\n",
       "      <td>0.590063</td>\n",
       "      <td>0.541282</td>\n",
       "      <td>0.508382</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>refugees</td>\n",
       "      <td>0.668289</td>\n",
       "      <td>0.592483</td>\n",
       "      <td>0.583147</td>\n",
       "      <td>0.505745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>death</td>\n",
       "      <td>0.823736</td>\n",
       "      <td>0.744577</td>\n",
       "      <td>0.717588</td>\n",
       "      <td>0.572977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>other_aid</td>\n",
       "      <td>0.665105</td>\n",
       "      <td>0.602251</td>\n",
       "      <td>0.594623</td>\n",
       "      <td>0.505071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>infrastructure_related</td>\n",
       "      <td>0.592649</td>\n",
       "      <td>0.568458</td>\n",
       "      <td>0.581859</td>\n",
       "      <td>0.502798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>transport</td>\n",
       "      <td>0.648653</td>\n",
       "      <td>0.611480</td>\n",
       "      <td>0.620134</td>\n",
       "      <td>0.528186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>buildings</td>\n",
       "      <td>0.771846</td>\n",
       "      <td>0.712188</td>\n",
       "      <td>0.676261</td>\n",
       "      <td>0.547277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>electricity</td>\n",
       "      <td>0.768343</td>\n",
       "      <td>0.661006</td>\n",
       "      <td>0.630122</td>\n",
       "      <td>0.503749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tools</td>\n",
       "      <td>0.499614</td>\n",
       "      <td>0.499304</td>\n",
       "      <td>0.496368</td>\n",
       "      <td>0.499923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hospitals</td>\n",
       "      <td>0.622053</td>\n",
       "      <td>0.556705</td>\n",
       "      <td>0.494571</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>shops</td>\n",
       "      <td>0.499923</td>\n",
       "      <td>0.499691</td>\n",
       "      <td>0.511908</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aid_centers</td>\n",
       "      <td>0.550999</td>\n",
       "      <td>0.544109</td>\n",
       "      <td>0.505539</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>other_infrastructure</td>\n",
       "      <td>0.572961</td>\n",
       "      <td>0.550697</td>\n",
       "      <td>0.561605</td>\n",
       "      <td>0.499839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>weather_related</td>\n",
       "      <td>0.846143</td>\n",
       "      <td>0.815147</td>\n",
       "      <td>0.791779</td>\n",
       "      <td>0.807176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>floods</td>\n",
       "      <td>0.803739</td>\n",
       "      <td>0.739366</td>\n",
       "      <td>0.776466</td>\n",
       "      <td>0.697761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>storm</td>\n",
       "      <td>0.870905</td>\n",
       "      <td>0.770711</td>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.722947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fire</td>\n",
       "      <td>0.541520</td>\n",
       "      <td>0.591825</td>\n",
       "      <td>0.545264</td>\n",
       "      <td>0.508319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.902520</td>\n",
       "      <td>0.854278</td>\n",
       "      <td>0.802242</td>\n",
       "      <td>0.862953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cold</td>\n",
       "      <td>0.699366</td>\n",
       "      <td>0.642023</td>\n",
       "      <td>0.591322</td>\n",
       "      <td>0.536232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>other_weather</td>\n",
       "      <td>0.651353</td>\n",
       "      <td>0.609417</td>\n",
       "      <td>0.604539</td>\n",
       "      <td>0.510702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>direct_report</td>\n",
       "      <td>0.767342</td>\n",
       "      <td>0.742739</td>\n",
       "      <td>0.751854</td>\n",
       "      <td>0.669805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label  roc_auc_SVC  roc_auc_MLPC  roc_auc_NB  roc_auc_RF\n",
       "0                  related     0.740768      0.757396    0.746812    0.619573\n",
       "1                  request     0.812441      0.792444    0.797583    0.718689\n",
       "2                    offer     0.521662      0.498535    0.497070    0.500000\n",
       "3              aid_related     0.758708      0.761365    0.736056    0.747421\n",
       "4             medical_help     0.713030      0.629825    0.691044    0.537495\n",
       "5         medical_products     0.730624      0.678370    0.681997    0.561335\n",
       "6        search_and_rescue     0.607963      0.580718    0.543553    0.516104\n",
       "7                 security     0.522627      0.517263    0.497766    0.500000\n",
       "8                 military     0.764392      0.664038    0.727779    0.517460\n",
       "9                    water     0.888361      0.792788    0.773098    0.655482\n",
       "10                    food     0.889475      0.835269    0.800844    0.729963\n",
       "11                 shelter     0.832422      0.768675    0.775942    0.656826\n",
       "12                clothing     0.771012      0.708376    0.657694    0.541159\n",
       "13                   money     0.719960      0.653919    0.578442    0.517573\n",
       "14          missing_people     0.590063      0.541282    0.508382    0.500000\n",
       "15                refugees     0.668289      0.592483    0.583147    0.505745\n",
       "16                   death     0.823736      0.744577    0.717588    0.572977\n",
       "17               other_aid     0.665105      0.602251    0.594623    0.505071\n",
       "18  infrastructure_related     0.592649      0.568458    0.581859    0.502798\n",
       "19               transport     0.648653      0.611480    0.620134    0.528186\n",
       "20               buildings     0.771846      0.712188    0.676261    0.547277\n",
       "21             electricity     0.768343      0.661006    0.630122    0.503749\n",
       "22                   tools     0.499614      0.499304    0.496368    0.499923\n",
       "23               hospitals     0.622053      0.556705    0.494571    0.500000\n",
       "24                   shops     0.499923      0.499691    0.511908    0.500000\n",
       "25             aid_centers     0.550999      0.544109    0.505539    0.500000\n",
       "26    other_infrastructure     0.572961      0.550697    0.561605    0.499839\n",
       "27         weather_related     0.846143      0.815147    0.791779    0.807176\n",
       "28                  floods     0.803739      0.739366    0.776466    0.697761\n",
       "29                   storm     0.870905      0.770711    0.814156    0.722947\n",
       "30                    fire     0.541520      0.591825    0.545264    0.508319\n",
       "31              earthquake     0.902520      0.854278    0.802242    0.862953\n",
       "32                    cold     0.699366      0.642023    0.591322    0.536232\n",
       "33           other_weather     0.651353      0.609417    0.604539    0.510702\n",
       "34           direct_report     0.767342      0.742739    0.751854    0.669805"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results1 = results_SVC.join(results_MLPC, lsuffix = '_SVC', rsuffix = '_MLPC').drop(columns = ['label_MLPC']).rename(columns = {'label_SVC':'label'})\n",
    "all_results2 = results_NB.join(results_RF, lsuffix = '_NB', rsuffix = '_RF').drop(columns = ['label_RF'])\n",
    "all_results = all_results1.join(all_results2).drop(columns = ['label_NB'])\n",
    "all_results[['label','roc_auc_SVC','roc_auc_MLPC','roc_auc_NB','roc_auc_RF']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using only nouns from the messages to reduce vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look of the vocabulary size with different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length with stop words:  25764\n",
      "Vocabulary length without stop words:  25469\n",
      "Vocabulary length without stop words with 1- and 2-word n-grams:  195253\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary length with stop words: ', len(MLPC_pipeline.named_steps['vect'].vocabulary_))\n",
    "print('Vocabulary length without stop words: ', len(model_NB.named_steps['vect'].vocabulary_))\n",
    "print('Vocabulary length without stop words with 1- and 2-word n-grams: ', len(model_SVC.named_steps['vect'].vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use NounExtractor from section 2. to extract nouns from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_N = NounsExtractor().transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19521x15945 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 144110 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countVectorizer = CountVectorizer(tokenizer=tokenize)\n",
    "countVectorizer.fit_transform(X_train_N)\n",
    "print('Vocabulary length with only nouns: ', len(countVectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit SVC model with the only nouns training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC pipeline training time with only nouns: 37.11 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "model_SVC.fit(X_train_N, y_train)\n",
    "stop = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length without stop words with 1- and 2-word n-grams:  107208\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary length only nouns without stop words with 1- and 2-word n-grams: ',\n",
    "      len(model_SVC.named_steps['vect'].vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.686758\n",
       "recall       0.675585\n",
       "f1           0.677456\n",
       "roc_auc      0.675585\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "y_pred = pd.DataFrame(model_SVC.predict(X_test), columns = y.columns)\n",
    "stop = timeit.default_timer()\n",
    "SVC_predict_time = stop - start\n",
    "results_SVC_N = show_results(y_test, y_pred, print_report = False)\n",
    "results_SVC_N.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model_MLPC.pickle','wb')\n",
    "pickle.dump(MLPC_pipeline_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model_RF.pickle','wb')\n",
    "pickle.dump(model_RF, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model_NB.pickle','wb')\n",
    "pickle.dump(model_NB, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model_SVC.pickle','wb')\n",
    "pickle.dump(model_SVC, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = [results_SVC['roc_auc'].mean(), results_MLPC['roc_auc'].mean(),\n",
    "                results_RF['roc_auc'].mean(), results_NB['roc_auc'].mean()]\n",
    "model_sizes = [37.5, 1590.0, 1020.0, 29.8]\n",
    "model_training = [SVC_training_time, MLPC_training_time, RF_training_time, NB_training_time]\n",
    "model_comparison = pd.DataFrame.from_dict({'model':['Linear SVC',  'MLPC', 'RF', 'NB'], 'ROC AUC':model_scores, \n",
    "                                          'size, MB':model_sizes, 'training time, s':model_training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>size, MB</th>\n",
       "      <th>training time, s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.703731</td>\n",
       "      <td>37.5</td>\n",
       "      <td>34.035804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.659678</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>1672.247248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.580015</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>535.568273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.647583</td>\n",
       "      <td>29.8</td>\n",
       "      <td>9.796344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model   ROC AUC  size, MB  training time, s\n",
       "0  Linear SVC  0.703731      37.5         34.035804\n",
       "1        MLPC  0.659678    1590.0       1672.247248\n",
       "2          RF  0.580015    1020.0        535.568273\n",
       "3          NB  0.647583      29.8          9.796344"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarkably simpler models such as multinomial naive bayes and linear support vector classification have shown similar or higher performance comparing to more complex models such as multilayer perceptron and random forest.\n",
    "<br>\n",
    "This may be due to the fact, that twitter messages are short, so simple analysis methods are sufficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
